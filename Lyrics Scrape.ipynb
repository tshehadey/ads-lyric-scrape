{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffdae053",
   "metadata": {},
   "source": [
    "# ADS 509 Module 1: APIs and Web Scraping\n",
    "\n",
    "This notebook has two parts. In the first part, you will scrape lyrics from AZLyrics.com. In the second part, you'll run code that verifies the completeness of your data pull.\n",
    "\n",
    "For this assignment you have chosen two musical artists who have at least 20 songs with lyrics on AZLyrics.com. We start with pulling some information and analyzing them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb4e286",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0ce8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "# for the lyrics scrape section\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict, Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "288b03d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = {\n",
    "    'mac miller': \"https://www.azlyrics.com/m/macmiller.html\",\n",
    "    'pop smoke': \"https://www.azlyrics.com/p/popsmoke.html\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ee155b",
   "metadata": {},
   "source": [
    "## A Note on Rate Limiting\n",
    "\n",
    "The lyrics site, www.azlyrics.com, does not have an explicit maximum on number of requests in any one time, but in our testing it appears that too many requests in too short a time will cause the site to stop returning lyrics pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceea4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_pages = defaultdict(list)\n",
    "\n",
    "for artist, artist_page in artists.items():\n",
    "    r = requests.get(artist_page)\n",
    "    time.sleep(5 + 10 * random.random())\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    for link in soup.select(\"div.listalbum-item a[href]\"):\n",
    "        href = link[\"href\"]\n",
    "        if href.startswith(\"/lyrics/\"):\n",
    "            full_link = \"https://www.azlyrics.com\" + href\n",
    "            lyrics_pages[artist].append(full_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dfa3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist, lp in lyrics_pages.items():\n",
    "    assert(len(set(lp)) > 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba14ed65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For mac miller we have 310.\n",
      "The full pull will take for this artist will take 0.86 hours.\n",
      "For pop smoke we have 106.\n",
      "The full pull will take for this artist will take 0.29 hours.\n"
     ]
    }
   ],
   "source": [
    "for artist, links in lyrics_pages.items():\n",
    "    print(f\"For {artist} we have {len(links)}.\")\n",
    "    print(f\"The full pull will take for this artist will take {round(len(links)*10/3600,2)} hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d92f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_filename_from_link(link):\n",
    "    if not link:\n",
    "        return None\n",
    "\n",
    "    name = link.replace(\"https\",\"\").replace(\"http\",\"\")\n",
    "    name = name.replace(\".html\",\"\")\n",
    "    name = name.replace(\"/lyrics/\",\"\")\n",
    "    name = name.replace(\"://\",\"\").replace(\".\",\"_\").replace(\"/\",\"_\")\n",
    "    name = name + \".txt\"\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d343fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(\"lyrics\"):\n",
    "    shutil.rmtree(\"lyrics/\")\n",
    "\n",
    "os.mkdir(\"lyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c470885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_stub = \"https://www.azlyrics.com\"\n",
    "start = time.time()\n",
    "\n",
    "total_pages = 0\n",
    "\n",
    "for artist in lyrics_pages:\n",
    "    folder = f\"lyrics/{artist}\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    for link in lyrics_pages[artist][:20]:\n",
    "        try:\n",
    "            r = requests.get(link)\n",
    "            time.sleep(5 + 10 * random.random())\n",
    "\n",
    "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "            title = soup.find(\"title\").get_text(strip=True)\n",
    "            divs = soup.find_all(\"div\", class_=False, id=False)\n",
    "            lyrics = divs[0].get_text(separator=\"\\n\").strip()\n",
    "\n",
    "            filename = generate_filename_from_link(link)\n",
    "            filepath = os.path.join(folder, filename)\n",
    "\n",
    "            with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(title + \"\\n\\n\" + lyrics)\n",
    "\n",
    "            total_pages += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to get {link} for {artist}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c60909fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total run time was 0.12 hours.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total run time was {round((time.time() - start)/3600, 2)} hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9abd936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text):\n",
    "    return re.findall(r'\\w+', text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b71d3a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For mac miller we have 20 files.\n",
      "For mac miller we have roughly 12582 words, 1835 are unique.\n",
      "For pop smoke we have 20 files.\n",
      "For pop smoke we have roughly 9296 words, 1358 are unique.\n"
     ]
    }
   ],
   "source": [
    "artist_folders = os.listdir(\"lyrics/\")\n",
    "artist_folders = [f for f in artist_folders if os.path.isdir(\"lyrics/\" + f)]\n",
    "\n",
    "for artist in artist_folders:\n",
    "    artist_files = os.listdir(\"lyrics/\" + artist)\n",
    "    artist_files = [f for f in artist_files if 'txt' in f or 'csv' in f or 'tsv' in f]\n",
    "\n",
    "    print(f\"For {artist} we have {len(artist_files)} files.\")\n",
    "\n",
    "    artist_words = []\n",
    "\n",
    "    for f_name in artist_files:\n",
    "        with open(\"lyrics/\" + artist + \"/\" + f_name, encoding=\"utf-8\") as infile:\n",
    "            artist_words.extend(words(infile.read()))\n",
    "\n",
    "    print(f\"For {artist} we have roughly {len(artist_words)} words, {len(set(artist_words))} are unique.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
